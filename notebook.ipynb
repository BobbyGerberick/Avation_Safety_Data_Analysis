{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import pandas.api.types as ptypes\n",
    "\n",
    "#pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Aviation_Data.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Event.Date to Date Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coerce 'Event.Date' into pandas date time object\n",
    "df[\"Event.Date\"] = pd.to_datetime(df['Event.Date'], format='%Y-%m-%d', errors = 'coerce')\n",
    "# Assert that Event.Date is not a datetime64 dtype:\n",
    "assert ptypes.is_datetime64_any_dtype(df['Event.Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Event.Id Column\n",
    "### This removes nulls from Event.Id, Investigation.Type, Accident.Number, and Event.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Event.Id' is NULL\n",
    "df_clean = df.dropna(subset=['Event.Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates using the Event.Id column\n",
    "df_clean1 = df_clean.drop_duplicates(subset=['Event.Id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping rows where NOT Event.Id null,\n",
    "# We now have a dataset where first 4 columns have no nulls\n",
    "# We think this makes sense because without an id or accident number, the event wasn't properly documented\n",
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset based on Event.Date\n",
    "- We wanted to only look at past 30 years because planes older than that likely no longer flying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to look at past 30 years of data:\n",
    "df_30 = df_clean[df_clean['Event.Date'] >= '1993-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Date Range\n",
    "print(df_30['Event.Date'].min())\n",
    "print(df_30['Event.Date'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Total Injuries Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Total Injuries Column\n",
    "df_30['Total.Injuries'] = df_30['Total.Fatal.Injuries'] + df_30['Total.Minor.Injuries'] + df_30['Total.Serious.Injuries'] \n",
    "# Sanity Check new 'Total.Injuries' Column:\n",
    "df_30[['Total.Injuries', 'Total.Fatal.Injuries', 'Total.Minor.Injuries', 'Total.Serious.Injuries']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Make and Model Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Make column (this gets rid of a lot of unique values)\n",
    "#Start by making everything lowercase\n",
    "df_clean1['Make'] = df_clean1['Make'].str.lower()\n",
    "#capitalize the beginning of each word\n",
    "df_clean1['Make'] = df_clean1['Make'].str.title()\n",
    "#Get rid of whitespace\n",
    "df_clean1['Make'] = df_clean1['Make'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the Model column (I don’t think this got rid of any unique values)\n",
    "#Start by making everything uppercase\n",
    "df_clean1['Model'] = df_clean1['Model'].str.upper()\n",
    "#Get rid of whitespace\n",
    "df_clean1['Model'] = df_clean1['Model'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean1['Model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Aircraft.Category Column:\n",
    "- Here we will throw out only those Aircraft.Category rows where Airplane or NULL\n",
    "- Concatenate Make and Model = Make_Model\n",
    "- Keep the rows that are (Aircraft.Category = NULL) ONLY IF...\n",
    "- The Make_Model value is one that exists in rows that are (Aircraft.Category = 'Airplane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of non airplane rows but keep the nulls\n",
    "#First fill nulls with ‘n/a’\n",
    "df_clean1['Aircraft.Category'].fillna('n/a', inplace=True)\n",
    "#Keep only rows with ‘Airplane’ or ‘n/a’\n",
    "df_clean2 = df_clean1.loc[(df_clean1['Aircraft.Category'] == 'Airplane') | (df_clean1['Aircraft.Category'] == 'n/a')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2['Aircraft.Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create concatenated Make.Model column:\n",
    "df_clean2[\"Make.Model\"] = df_clean2['Make'].astype(str) +\"_\"+ df_clean2[\"Model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean2[\"Make.Model\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview counts for each Make.Model, grouped on Aircraft.Category:\n",
    "df_clean2.groupby(['Aircraft.Category','Make.Model']).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into two dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate a dataframe only containing rows where category is Airplane:\n",
    "df_plane = df_clean2[df_clean2['Aircraft.Category'] == 'Airplane']\n",
    "# And one for category = n/a:\n",
    "df_na = df_clean2[df_clean2['Aircraft.Category'] == 'n/a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category = Airplane\n",
    "\n",
    "# 27,520 rows\n",
    "# 7,484 unique Make.Model values\n",
    "print(df_plane.shape)\n",
    "print(df_plane['Make.Model'].unique().shape)\n",
    "df_plane['Make.Model'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category = n/a\n",
    "\n",
    "# 55,770 rows\n",
    "# 11,038 unique Make.Model values\n",
    "print(df_na.shape)\n",
    "print(df_na['Make.Model'].unique().shape)\n",
    "df_na['Make.Model'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the **category = n/a** rows to only contain the Make.Model values of Airplanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all of the unique values of \"Make.Model\" where aircraft.category = 'Aiplane':\n",
    "airplane_make_model_list = list(df_plane['Make.Model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to original dataframe \"df_clean2\" before we split it, and filter to only Make.Model values in airplane_make_model_list\n",
    "df_ap_mm = df_clean2[df_clean2['Make.Model'].isin(airplane_make_model_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check:\n",
    "# Number of rows where 'Aircraft.Category' = 'Airplane' vs. Total Rows\n",
    "print(df_ap_mm['Aircraft.Category'].value_counts())\n",
    "print(df_ap_mm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we only have Make.Model rows that we know are Airplanes, so we can replace all 'n/a' values with 'Airplane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'n/a' value with 'Airplane':\n",
    "df_ap_mm['Aircraft.Category'] = df_ap_mm['Aircraft.Category'].replace(['n/a'], 'Airplane')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
